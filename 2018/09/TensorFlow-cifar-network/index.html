<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="机器学习，深度学习，强化学习，算法，Linux">
  <meta name="author" content="seven">
  <meta name="keywords" content="">
  <title>TensorFlow-cifar10-图像分类之网络结构 - SimpleAI</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
<meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/feed.xml" title="SimpleAI" type="application/atom+xml">
</head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Simple AI</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" href="#" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                文档
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="http://ai-club.gitee.io/tensorflow-book/" target="_blank" rel="noopener">
                    
                    TensorFlow 2系列教程
                  </a>
                
              </div>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2018-09-07 10:00">
      2018年9月7日 上午
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      2.1k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      39
       分钟
    </span>
  

  
  
    
      <!-- LeanCloud 统计文章PV -->
      <span id="leancloud-post-views-container" class="post-meta" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="leancloud-post-views"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
              <p class="note note-info">
                
                  本文最后更新于：6 天前
                
              </p>
            
            <article class="markdown-body">
              <h3 id="LeNet网络："><a href="#LeNet网络：" class="headerlink" title="LeNet网络："></a><strong>LeNet网络</strong>：</h3><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">LeNet</span><span class="hljs-params">(inputs)</span>:</span>

    mu = <span class="hljs-number">0</span>
    sigma = <span class="hljs-number">0.1</span>
    print(inputs.shape)
    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> 第一层卷积：输入=32x32x3, 输出=28x28x6</span>
    conv1_w = tf.Variable(tf.truncated_normal(shape=[<span class="hljs-number">5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">3</span>, <span class="hljs-number">6</span>], mean=mu, stddev=sigma))
    conv1_b = tf.Variable(tf.zeros(<span class="hljs-number">6</span>))

    conv1 = tf.nn.conv2d(inputs, conv1_w, strides=[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], padding=<span class="hljs-string">'VALID'</span>) + conv1_b
    print(conv1.shape)
    <span class="hljs-comment"># 激活函数</span>
    conv1_out = tf.nn.relu(conv1)

    <span class="hljs-comment"># 池化层， 输入=28x28x6, 输出=14x14x6</span>
    pool_1 = tf.nn.max_pool(conv1_out, ksize=[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>], strides=[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>], padding=<span class="hljs-string">'VALID'</span>)
    print(pool_1.shape)

    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> 第二层卷积： 输入=14x14x6， 输出=10x10x16</span>
    conv2_w = tf.Variable(tf.truncated_normal(shape=[<span class="hljs-number">5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">16</span>], mean=mu, stddev=sigma))
    conv2_b = tf.Variable(tf.zeros(<span class="hljs-number">16</span>))

    conv2 = tf.nn.conv2d(pool_1, conv2_w, strides=[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], padding=<span class="hljs-string">'VALID'</span>) + conv2_b
    print(conv2.shape)
    <span class="hljs-comment"># 激活函数</span>
    conv2_out = tf.nn.relu(conv2)

    <span class="hljs-comment"># 池化层， 输入=10x10x16, 输出=5x5x16</span>
    pool_2 = tf.nn.max_pool(conv2_out, ksize=[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>], strides=[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>], padding=<span class="hljs-string">'VALID'</span>)
    print(pool_2.shape)
    <span class="hljs-comment"># Flatten 输入=5x5x16， 输出=400</span>
    pool_2_flat = tf.reshape(pool_2, [<span class="hljs-number">-1</span>, <span class="hljs-number">400</span>])

    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> 第三层全连接层， 输入=400， 输出=120</span>
    fc1_w = tf.Variable(tf.truncated_normal(shape=[<span class="hljs-number">400</span>, <span class="hljs-number">120</span>], mean=mu, stddev=sigma))
    fc1_b = tf.Variable(tf.zeros(<span class="hljs-number">120</span>))

    fc1 = tf.matmul(pool_2_flat, fc1_w) + fc1_b

    <span class="hljs-comment"># 激活函数</span>
    fc1_out = tf.nn.relu(fc1)
    print(fc1_out.shape)

    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> 第四层全连接层： 输入=120， 输出=84</span>
    fc2_w = tf.Variable(tf.truncated_normal(shape=[<span class="hljs-number">120</span>, <span class="hljs-number">84</span>], mean=mu, stddev=sigma))
    fc2_b = tf.Variable(tf.zeros(<span class="hljs-number">84</span>))

    fc2 = tf.matmul(fc1_out, fc2_w) + fc2_b

    <span class="hljs-comment"># 激活函数</span>
    fc2_out = tf.nn.relu(fc2)
    print(fc2_out.shape)

    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> 第五层全连接层： 输入=84， 输出=10</span>
    fc3_w = tf.Variable(tf.truncated_normal(shape=[<span class="hljs-number">84</span>, <span class="hljs-number">10</span>], mean=mu, stddev=sigma))
    fc3_b = tf.Variable(tf.zeros(<span class="hljs-number">10</span>))

    fc3_out = tf.matmul(fc2_out, fc3_w) + fc3_b
    print(fc3_out.shape)

    <span class="hljs-keyword">return</span> fc3_out</code></pre>

<h3 id="AlexNet网络："><a href="#AlexNet网络：" class="headerlink" title="AlexNet网络："></a><strong>AlexNet网络</strong>：</h3><pre><code class="hljs python"><span class="hljs-comment"># 卷积操作</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">conv2d</span><span class="hljs-params">(name, l_input, w, b)</span>:</span>
    <span class="hljs-keyword">return</span> tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(l_input, w, strides=[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], padding=<span class="hljs-string">'SAME'</span>), b), name=name)


<span class="hljs-comment"># 最大下采样操作</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">max_pool</span><span class="hljs-params">(name, l_input, k)</span>:</span>
    <span class="hljs-keyword">return</span> tf.nn.max_pool(l_input, ksize=[<span class="hljs-number">1</span>, k, k, <span class="hljs-number">1</span>], strides=[<span class="hljs-number">1</span>, k, k, <span class="hljs-number">1</span>], padding=<span class="hljs-string">'SAME'</span>, name=name)


<span class="hljs-comment"># 归一化操作</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">norm</span><span class="hljs-params">(name, l_input, lsize=<span class="hljs-number">4</span>)</span>:</span>
    <span class="hljs-keyword">return</span> tf.nn.lrn(l_input, lsize, bias=<span class="hljs-number">1.0</span>, alpha=<span class="hljs-number">0.001</span> / <span class="hljs-number">9.0</span>, beta=<span class="hljs-number">0.75</span>, name=name)


<span class="hljs-comment"># 定义整个网络</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">alex_net</span><span class="hljs-params">(_X, _weights, _biases, _dropout)</span>:</span>
    <span class="hljs-comment"># 向量转为矩阵</span>
    <span class="hljs-comment"># _X = tf.reshape(_X, shape=[-1, 28, 28, 3])</span>
    print(_X.shape)
    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> 第一层卷积：</span>
    conv1 = conv2d(<span class="hljs-string">'conv1'</span>, _X, _weights[<span class="hljs-string">'wc1'</span>], _biases[<span class="hljs-string">'bc1'</span>])
    <span class="hljs-comment"># 下采样层</span>
    pool1 = max_pool(<span class="hljs-string">'pool1'</span>, conv1, k=<span class="hljs-number">2</span>)
    <span class="hljs-comment"># 归一化层</span>
    norm1 = norm(<span class="hljs-string">'norm1'</span>, pool1, lsize=<span class="hljs-number">4</span>)
    print(norm1.shape)
    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> 第二层卷积：</span>
    conv2 = conv2d(<span class="hljs-string">'conv2'</span>, norm1, _weights[<span class="hljs-string">'wc2'</span>], _biases[<span class="hljs-string">'bc2'</span>])
    <span class="hljs-comment"># 下采样</span>
    pool2 = max_pool(<span class="hljs-string">'pool2'</span>, conv2, k=<span class="hljs-number">2</span>)
    <span class="hljs-comment"># 归一化</span>
    norm2 = norm(<span class="hljs-string">'norm2'</span>, pool2, lsize=<span class="hljs-number">4</span>)
    print(norm2.shape)
    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> 第三层卷积：</span>
    conv3 = conv2d(<span class="hljs-string">'conv3'</span>, norm2, _weights[<span class="hljs-string">'wc3'</span>], _biases[<span class="hljs-string">'bc3'</span>])
    <span class="hljs-comment"># 归一化</span>
    norm3 = norm(<span class="hljs-string">'norm3'</span>, conv3, lsize=<span class="hljs-number">4</span>)
    print(norm3.shape)
    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> 第四层卷积</span>
    <span class="hljs-comment"># 卷积</span>
    conv4 = conv2d(<span class="hljs-string">'conv4'</span>, norm3, _weights[<span class="hljs-string">'wc4'</span>], _biases[<span class="hljs-string">'bc4'</span>])
    <span class="hljs-comment"># 归一化</span>
    norm4 = norm(<span class="hljs-string">'norm4'</span>, conv4, lsize=<span class="hljs-number">4</span>)
    print(norm4.shape)
    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> 第五层卷积</span>
    <span class="hljs-comment"># 卷积</span>
    conv5 = conv2d(<span class="hljs-string">'conv5'</span>, norm4, _weights[<span class="hljs-string">'wc5'</span>], _biases[<span class="hljs-string">'bc5'</span>])
    <span class="hljs-comment"># 下采样</span>
    pool5 = max_pool(<span class="hljs-string">'pool5'</span>, conv5, k=<span class="hljs-number">2</span>)
    <span class="hljs-comment"># 归一化</span>
    norm5 = norm(<span class="hljs-string">'norm5'</span>, pool5, lsize=<span class="hljs-number">4</span>)
    print(norm5.shape)
    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> 第六层全连接层</span>
    <span class="hljs-comment"># 先把特征图转为向量</span>
    dense1 = tf.reshape(norm5, [<span class="hljs-number">-1</span>, _weights[<span class="hljs-string">'wd1'</span>].get_shape().as_list()[<span class="hljs-number">0</span>]])
    dense1 = tf.nn.relu(tf.matmul(dense1, _weights[<span class="hljs-string">'wd1'</span>]) + _biases[<span class="hljs-string">'bd1'</span>], name=<span class="hljs-string">'fc1'</span>)
    dense1 = tf.nn.dropout(dense1, _dropout)
    print(dense1.shape)
    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> 第七层全连接层：</span>
    dense2 = tf.nn.relu(tf.matmul(dense1, _weights[<span class="hljs-string">'wd2'</span>]) + _biases[<span class="hljs-string">'bd2'</span>], name=<span class="hljs-string">'fc2'</span>)  <span class="hljs-comment"># Relu activation</span>
    dense2 = tf.nn.dropout(dense2, _dropout)
    print(dense2.shape)
    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> 第八层全连接层：</span>
    <span class="hljs-comment"># 网络输出层</span>
    out = tf.matmul(dense2, _weights[<span class="hljs-string">'out'</span>]) + _biases[<span class="hljs-string">'out'</span>]
    print(out.shape)
    <span class="hljs-keyword">return</span> out</code></pre>

<h3 id="VGG16Net网络："><a href="#VGG16Net网络：" class="headerlink" title="VGG16Net网络："></a><strong>VGG16Net网络</strong>：</h3><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">VGG16</span><span class="hljs-params">(inputs)</span>:</span>
    print(inputs.shape)
    <span class="hljs-comment"># (32x32x3) --&gt; (32x32x64)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_1'</span>):
         conv_1_out = tf.layers.conv2d(inputs, <span class="hljs-number">64</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_1_out.shape)
    <span class="hljs-comment"># (32x32x64) --&gt; (32x32x64)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_2'</span>):
        conv_2_out = tf.layers.conv2d(conv_1_out, <span class="hljs-number">64</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                      padding=<span class="hljs-string">'same'</span>,
                                      activation=tf.nn.relu,
                                      kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_2_out.shape)
    <span class="hljs-comment"># (32x32x64) --&gt; (16x16x64)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'pool_1'</span>):
        pool_1_out = tf.layers.max_pooling2d(conv_2_out, pool_size=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], strides=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], padding=<span class="hljs-string">'same'</span>)

    print(pool_1_out.shape)
    <span class="hljs-comment"># (16x16x64) --&gt; (16x16x128)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_3'</span>):
         conv_3_out = tf.layers.conv2d(pool_1_out, <span class="hljs-number">128</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_3_out.shape)
    <span class="hljs-comment"># (16x16x128) --&gt; (16x16x128)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_4'</span>):
         conv_4_out = tf.layers.conv2d(conv_3_out, <span class="hljs-number">128</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_4_out.shape)
    <span class="hljs-comment"># (16x16x128) --&gt; (8x8x128)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'pool_2'</span>):
        pool_2_out = tf.layers.max_pooling2d(conv_4_out, pool_size=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], strides=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], padding=<span class="hljs-string">'same'</span>)

    print(pool_2_out.shape)
    <span class="hljs-comment"># (8x8x128) --&gt; (8x8x256)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_5'</span>):
         conv_5_out = tf.layers.conv2d(pool_2_out, <span class="hljs-number">256</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_5_out.shape)
    <span class="hljs-comment"># (8x8x256) --&gt; (8x8x256)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_6'</span>):
         conv_6_out = tf.layers.conv2d(conv_5_out, <span class="hljs-number">256</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_6_out.shape)
    <span class="hljs-comment"># (8x8x256) --&gt; (8x8x256)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_7'</span>):
        conv_7_out = tf.layers.conv2d(conv_6_out, <span class="hljs-number">256</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                      padding=<span class="hljs-string">'same'</span>,
                                      activation=tf.nn.relu,
                                      kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_7_out.shape)
    <span class="hljs-comment"># (8x8x256) --&gt; (4x4x256)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'pool_3'</span>):
        pool_3_out = tf.layers.max_pooling2d(conv_7_out, pool_size=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], strides=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], padding=<span class="hljs-string">'same'</span>)

    print(pool_3_out.shape)
    <span class="hljs-comment"># (4x4x256) --&gt; (4x4x512)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_8'</span>):
        conv_8_out = tf.layers.conv2d(pool_3_out, <span class="hljs-number">512</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                      padding=<span class="hljs-string">'same'</span>,
                                      activation=tf.nn.relu,
                                      kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_8_out.shape)
    <span class="hljs-comment"># (4x4x512) --&gt; (4x4x512)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_9'</span>):
        conv_9_out = tf.layers.conv2d(conv_8_out, <span class="hljs-number">512</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                      padding=<span class="hljs-string">'same'</span>,
                                      activation=tf.nn.relu,
                                      kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_9_out.shape)
    <span class="hljs-comment"># (4x4x512) --&gt; (4x4x512)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_10'</span>):
        conv_10_out = tf.layers.conv2d(conv_9_out, <span class="hljs-number">512</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_10_out.shape)
    <span class="hljs-comment"># (4x4x512) --&gt; (2x2x512)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'pool_4'</span>):
        pool_4_out = tf.layers.max_pooling2d(conv_10_out, pool_size=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], strides=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], padding=<span class="hljs-string">'same'</span>)

    print(pool_4_out.shape)
    <span class="hljs-comment"># (2x2x512) --&gt; (2x2x512)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_11'</span>):
        conv_11_out = tf.layers.conv2d(pool_4_out, <span class="hljs-number">512</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_11_out.shape)
    <span class="hljs-comment"># (2x2x512) --&gt; (2x2x512)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_12'</span>):
        conv_12_out = tf.layers.conv2d(conv_11_out, <span class="hljs-number">512</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_12_out.shape)
    <span class="hljs-comment"># (2x2x512) --&gt; (2x2x512)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_13'</span>):
        conv_13_out = tf.layers.conv2d(conv_12_out, <span class="hljs-number">512</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_13_out.shape)
    <span class="hljs-comment"># (2x2x512) --&gt; (1x1x512)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'pool_5'</span>):
        pool_5_out = tf.layers.max_pooling2d(conv_13_out, pool_size=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], strides=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], padding=<span class="hljs-string">'same'</span>)

    print(pool_5_out.shape)
    <span class="hljs-comment"># (1x1x512) --&gt; 512</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'fc_1'</span>):
        pool_5_outz_flat = tf.layers.flatten(pool_5_out)
        fc_1_out = tf.layers.dense(pool_5_outz_flat, <span class="hljs-number">512</span>, activation=tf.nn.relu)
        fc_1_drop = tf.nn.dropout(fc_1_out, keep_prob=config.keep_prob)
    print(fc_1_drop.shape)
    <span class="hljs-comment"># 512 --&gt; 512</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'fc_2'</span>):
        fc_2_out = tf.layers.dense(fc_1_drop, <span class="hljs-number">512</span>, activation=tf.nn.relu)
        fc_2_drop = tf.nn.dropout(fc_2_out, keep_prob=config.keep_prob)
    print(fc_2_drop.shape)
    <span class="hljs-comment"># 512 --&gt; 10</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'fc_3'</span>):
        fc_3_out = tf.layers.dense(fc_2_drop, <span class="hljs-number">10</span>, activation=<span class="hljs-literal">None</span>)
    print(fc_3_out.shape)

    <span class="hljs-keyword">return</span> fc_3_out</code></pre>

<h3 id="VGG19Net"><a href="#VGG19Net" class="headerlink" title="VGG19Net:"></a><strong>VGG19Net</strong>:</h3><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">VGG19</span><span class="hljs-params">(inputs)</span>:</span>
    print(inputs.shape)
    <span class="hljs-comment"># (32x32x3) --&gt; (32x32x64)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_1'</span>):
         conv_1_out = tf.layers.conv2d(inputs, <span class="hljs-number">64</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_1_out.shape)
    <span class="hljs-comment"># (32x32x64) --&gt; (32x32x64)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_2'</span>):
        conv_2_out = tf.layers.conv2d(conv_1_out, <span class="hljs-number">64</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                      padding=<span class="hljs-string">'same'</span>,
                                      activation=tf.nn.relu,
                                      kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_2_out.shape)
    <span class="hljs-comment"># (32x32x64) --&gt; (16x16x64)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'pool_1'</span>):
        pool_1_out = tf.layers.max_pooling2d(conv_2_out, pool_size=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], strides=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], padding=<span class="hljs-string">'same'</span>)

    print(pool_1_out.shape)
    <span class="hljs-comment"># (16x16x64) --&gt; (16x16x128)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_3'</span>):
         conv_3_out = tf.layers.conv2d(pool_1_out, <span class="hljs-number">128</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_3_out.shape)
    <span class="hljs-comment"># (16x16x128) --&gt; (16x16x128)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_4'</span>):
         conv_4_out = tf.layers.conv2d(conv_3_out, <span class="hljs-number">128</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_4_out.shape)
    <span class="hljs-comment"># (16x16x128) --&gt; (8x8x128)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'pool_2'</span>):
        pool_2_out = tf.layers.max_pooling2d(conv_4_out, pool_size=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], strides=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], padding=<span class="hljs-string">'same'</span>)

    print(pool_2_out.shape)
    <span class="hljs-comment"># (8x8x128) --&gt; (8x8x256)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_5'</span>):
         conv_5_out = tf.layers.conv2d(pool_2_out, <span class="hljs-number">256</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_5_out.shape)
    <span class="hljs-comment"># (8x8x256) --&gt; (8x8x256)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_6'</span>):
         conv_6_out = tf.layers.conv2d(conv_5_out, <span class="hljs-number">256</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_6_out.shape)
    <span class="hljs-comment"># (8x8x256) --&gt; (8x8x256)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_7'</span>):
        conv_7_out = tf.layers.conv2d(conv_6_out, <span class="hljs-number">256</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                      padding=<span class="hljs-string">'same'</span>,
                                      activation=tf.nn.relu,
                                      kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_7_out.shape)
    <span class="hljs-comment"># (8x8x256) --&gt; (8x8x256)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_8'</span>):
        conv_8_out = tf.layers.conv2d(conv_7_out, <span class="hljs-number">256</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                      padding=<span class="hljs-string">'same'</span>,
                                      activation=tf.nn.relu,
                                      kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_8_out.shape)
    <span class="hljs-comment"># (8x8x256) --&gt; (4x4x256)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'pool_3'</span>):
        pool_3_out = tf.layers.max_pooling2d(conv_8_out, pool_size=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], strides=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], padding=<span class="hljs-string">'same'</span>)

    print(pool_3_out.shape)
    <span class="hljs-comment"># (4x4x256) --&gt; (4x4x512)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_9'</span>):
        conv_9_out = tf.layers.conv2d(pool_3_out, <span class="hljs-number">512</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                      padding=<span class="hljs-string">'same'</span>,
                                      activation=tf.nn.relu,
                                      kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_9_out.shape)
    <span class="hljs-comment"># (4x4x512) --&gt; (4x4x512)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_10'</span>):
        conv_10_out = tf.layers.conv2d(conv_9_out, <span class="hljs-number">512</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_10_out.shape)
    <span class="hljs-comment"># (4x4x512) --&gt; (4x4x512)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_11'</span>):
        conv_11_out = tf.layers.conv2d(conv_10_out, <span class="hljs-number">512</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_11_out.shape)
    <span class="hljs-comment"># (4x4x512) --&gt; (4x4x512)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_12'</span>):
        conv_12_out = tf.layers.conv2d(conv_11_out, <span class="hljs-number">512</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_12_out.shape)
    <span class="hljs-comment"># (4x4x512) --&gt; (2x2x512)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'pool_4'</span>):
        pool_4_out = tf.layers.max_pooling2d(conv_12_out, pool_size=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], strides=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], padding=<span class="hljs-string">'same'</span>)

    print(pool_4_out.shape)
    <span class="hljs-comment"># (2x2x512) --&gt; (2x2x512)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_13'</span>):
        conv_13_out = tf.layers.conv2d(pool_4_out, <span class="hljs-number">512</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_13_out.shape)
    <span class="hljs-comment"># (2x2x512) --&gt; (2x2x512)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_14'</span>):
        conv_14_out = tf.layers.conv2d(conv_13_out, <span class="hljs-number">512</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_14_out.shape)
    <span class="hljs-comment"># (2x2x512) --&gt; (2x2x512)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_15'</span>):
        conv_15_out = tf.layers.conv2d(conv_14_out, <span class="hljs-number">512</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_15_out.shape)
    <span class="hljs-comment"># (2x2x512) --&gt; (2x2x512)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'conv_16'</span>):
        conv_16_out = tf.layers.conv2d(conv_15_out, <span class="hljs-number">512</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                                       padding=<span class="hljs-string">'same'</span>,
                                       activation=tf.nn.relu,
                                       kernel_initializer=tf.truncated_normal_initializer(mean=<span class="hljs-number">0.</span>, stddev=<span class="hljs-number">0.1</span>))
    print(conv_16_out.shape)
    <span class="hljs-comment"># (2x2x512) --&gt; (1x1x512)</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'pool_5'</span>):
        pool_5_out = tf.layers.max_pooling2d(conv_16_out, pool_size=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], strides=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], padding=<span class="hljs-string">'same'</span>)

    print(pool_5_out.shape)
    <span class="hljs-comment"># (1x1x512) --&gt; 512</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'fc_1'</span>):
        pool_5_outz_flat = tf.layers.flatten(pool_5_out)
        fc_1_out = tf.layers.dense(pool_5_outz_flat, <span class="hljs-number">512</span>, activation=tf.nn.relu)
        fc_1_drop = tf.nn.dropout(fc_1_out, keep_prob=config.keep_prob)
    print(fc_1_drop.shape)
    <span class="hljs-comment"># 512 --&gt; 512</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'fc_2'</span>):
        fc_2_out = tf.layers.dense(fc_1_drop, <span class="hljs-number">512</span>, activation=tf.nn.relu)
        fc_2_drop = tf.nn.dropout(fc_2_out, keep_prob=config.keep_prob)
    print(fc_2_drop.shape)
    <span class="hljs-comment"># 512 --&gt; 10</span>
    <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'fc_3'</span>):
        fc_3_out = tf.layers.dense(fc_2_drop, <span class="hljs-number">10</span>, activation=<span class="hljs-literal">None</span>)
    print(fc_3_out.shape)

    <span class="hljs-keyword">return</span> fc_3_out</code></pre>


            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/TensorFlow/">TensorFlow</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
                    
                      <a class="hover-with-bg" href="/tags/TensorFlow/">TensorFlow</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2018/09/TensorFlow-cifar-train/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">TensorFlow-cifar10-图像分类之训练模型及可视化数据</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2018/09/TensorFlow-cifar/">
                        <span class="hidden-mobile">TensorFlow-cifar10-图像分类之数据预处理及配置</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <div id="vcomments"></div>
  <script type="text/javascript">
    function loadValine() {
      addScript('https://cdn.staticfile.org/valine/1.4.14/Valine.min.js', function () {
        new Valine({
          el: "#vcomments",
          app_id: "npIvw4jbBhD0KtfOx9hHpPze-gzGzoHsz",
          app_key: "yLh6Ux5MbbkV0xFWnQEMce1j",
          placeholder: "说点什么",
          path: window.location.pathname,
          avatar: "retro",
          meta: ["nick","mail","link"],
          pageSize: "10",
          lang: "zh-CN",
          highlight: true,
          recordIP: false,
          serverURLs: "",
        });
      });
    }
    createObserver(loadValine, 'vcomments');
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://valine.js.org" target="_blank" rel="nofollow noopener noopener">comments
      powered by Valine.</a></noscript>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
     <div>
      <a href="http://0520.tech" target="_blank" rel="nofollow noopener"><span>Seven</span></a>
      <i class="iconfont icon-love"></i>
      <a href="http://0520.tech" target="_blank" rel="nofollow noopener"><span>2020</span></a>
    </div>
    <div>
      <span id="timeDate">载入天数...</span>
      <span id="times">载入时分秒...</span>
      <script>
      var now = new Date();
      function createtime(){
          var grt= new Date("02/14/2017 00:00:00");//此处修改你的建站时间或者网站上线时间
          now.setTime(now.getTime()+250);
          days = (now - grt ) / 1000 / 60 / 60 / 24;
          dnum = Math.floor(days);
          hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum);
          hnum = Math.floor(hours);
          if(String(hnum).length ==1 ){
              hnum = "0" + hnum;
          }
          minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
          mnum = Math.floor(minutes);
          if(String(mnum).length ==1 ){
                    mnum = "0" + mnum;
          }
          seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
          snum = Math.round(seconds);
          if(String(snum).length ==1 ){
                    snum = "0" + snum;
          }
          document.getElementById("timeDate").innerHTML = "本站安全运行&nbsp"+dnum+"&nbsp天";
          document.getElementById("times").innerHTML = hnum + "&nbsp小时&nbsp" + mnum + "&nbsp分&nbsp" + snum + "&nbsp秒";
      }
      setInterval("createtime()",250);
      </script>
    </div>
    
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "TensorFlow-cifar10-图像分类之网络结构&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script>

  













  
    <!-- Baidu Analytics -->
    <script defer>
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?480cc781425698544787d293ee99ce7c";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
  

  

  

  

  

  





</body>
</html>
